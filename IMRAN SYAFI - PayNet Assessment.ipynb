{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b43a92a0-320a-4fd5-bf32-141073378b6d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, from_json, to_timestamp, from_unixtime, from_utc_timestamp\n",
    "from pyspark.sql.functions import date_format, regexp_replace, split, expr, sha2, count, when, trim\n",
    "from pyspark.sql.types import StructType, StringType\n",
    "from pyspark.sql.functions import udf\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "filepath = 'dbfs:/Workspace/Users/imran.syafi/cc_sample_transaction.json'\n",
    "\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"test\").getOrCreate()\n",
    "\n",
    "df_spark = spark.read.json(filepath)\n",
    "\n",
    "personal_detail_schema = StructType() \\\n",
    "    .add(\"person_name\", StringType()) \\\n",
    "    .add(\"gender\", StringType()) \\\n",
    "    .add(\"address\", StringType()) \\\n",
    "    .add(\"lat\", StringType()) \\\n",
    "    .add(\"long\", StringType()) \\\n",
    "    .add(\"city_pop\", StringType()) \\\n",
    "    .add(\"job\", StringType()) \\\n",
    "    .add(\"dob\", StringType())\n",
    "\n",
    "df_parsed = df_spark.withColumn(\"personal\", from_json(col(\"personal_detail\"), personal_detail_schema))\n",
    "\n",
    "address_schema = StructType() \\\n",
    "    .add(\"street\", StringType()) \\\n",
    "    .add(\"city\", StringType()) \\\n",
    "    .add(\"state\", StringType()) \\\n",
    "    .add(\"zip\", StringType())\n",
    "\n",
    "df_with_address = df_parsed.withColumn(\"address_struct\", from_json(col(\"personal.address\"), address_schema))\n",
    "\n",
    "df_flat = df_with_address \\\n",
    "    .withColumn(\"person_name\", col(\"personal.person_name\")) \\\n",
    "    .withColumn(\"gender\", col(\"personal.gender\")) \\\n",
    "    .withColumn(\"lat\", col(\"personal.lat\")) \\\n",
    "    .withColumn(\"long\", col(\"personal.long\")) \\\n",
    "    .withColumn(\"city_pop\", col(\"personal.city_pop\")) \\\n",
    "    .withColumn(\"job\", col(\"personal.job\")) \\\n",
    "    .withColumn(\"dob\", col(\"personal.dob\")) \\\n",
    "    .withColumn(\"street\", col(\"address_struct.street\")) \\\n",
    "    .withColumn(\"city\", col(\"address_struct.city\")) \\\n",
    "    .withColumn(\"state\", col(\"address_struct.state\")) \\\n",
    "    .withColumn(\"zip\", col(\"address_struct.zip\"))\n",
    "\n",
    "df_flat = df_flat.drop(\"personal\", \"personal_detail\", \"address_struct\")\n",
    "\n",
    "df_flat.printSchema()\n",
    "df_flat.display()\n",
    "df_flat.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "02bc8f32-231a-4181-9ed0-aad5f25b5151",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Timestamp Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f810953-045c-4542-b125-e4cb342c24f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_flat = df_flat.withColumn(\n",
    "    \"trans_date_trans_time_fmt\", \n",
    "    date_format(\n",
    "        from_utc_timestamp(to_timestamp(\"trans_date_trans_time\", \"yyyy-MM-dd HH:mm:ss\"), \"Asia/Kuala_Lumpur\"),\n",
    "        \"yyyy-MM-dd HH:mm:ss.SSSSSS Z\"\n",
    "    )\n",
    ")\n",
    "df_flat = df_flat.drop(\"trans_date_trans_time\").withColumnRenamed(\"trans_date_trans_time_fmt\", \"trans_date_trans_time\")\n",
    "\n",
    "df_flat = df_flat.withColumn(\n",
    "    \"merch_last_update_time_fmt\",\n",
    "    date_format(\n",
    "        from_utc_timestamp(\n",
    "            from_unixtime(col(\"merch_last_update_time\") / 1000),\n",
    "            \"Asia/Kuala_Lumpur\"\n",
    "        ),\n",
    "        \"yyyy-MM-dd HH:mm:ss.SSSSSS Z\"\n",
    "    )\n",
    ")\n",
    "df_flat = df_flat.drop(\"merch_last_update_time\").withColumnRenamed(\"merch_last_update_time_fmt\", \"merch_last_update_time\")\n",
    "\n",
    "df_flat = df_flat.withColumn(\n",
    "    \"merch_eff_time_fmt\",\n",
    "    date_format(\n",
    "        from_utc_timestamp(\n",
    "            from_unixtime(col(\"merch_eff_time\") / 1_000_000),\n",
    "            \"Asia/Kuala_Lumpur\"\n",
    "        ),\n",
    "        \"yyyy-MM-dd HH:mm:ss.SSSSSS Z\"\n",
    "    )\n",
    ")\n",
    "df_flat = df_flat.drop(\"merch_eff_time\").withColumnRenamed(\"merch_eff_time_fmt\", \"merch_eff_time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "295cf9a1-27d3-4aa8-ad15-db978f69876d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Name Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18aa78ce-b017-4730-913b-77d5c8b11f9a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_flat = df_flat.withColumn(\n",
    "    \"person_name_cleaned\",\n",
    "    regexp_replace(\"person_name\", r\"[^a-zA-Z0-9,]\", \",\")\n",
    ")\n",
    "df_flat = df_flat.withColumn(\n",
    "    \"person_name_cleaned\",\n",
    "    regexp_replace(\"person_name_cleaned\", r\"(eeeee|NOOOO)\", \"\")\n",
    ")\n",
    "df_flat = df_flat.withColumn(\n",
    "    \"person_name_cleaned\",\n",
    "    regexp_replace(\"person_name_cleaned\", r\"\\s+\", \"\")\n",
    ")\n",
    "df_flat = df_flat.withColumn(\n",
    "    \"name_parts_filtered\",\n",
    "    expr(\"\"\"\n",
    "        filter(split(person_name_cleaned, \",\"), x -> x != \"\")\n",
    "    \"\"\")\n",
    ")\n",
    "df_flat = df_flat.withColumn(\n",
    "    \"cleaned_name\",\n",
    "    expr(\"concat_ws(' ', name_parts_filtered)\")\n",
    ")\n",
    "df_flat = df_flat.withColumn(\n",
    "    \"first\",\n",
    "    expr(\"split(cleaned_name, ' ')[0]\")\n",
    ").withColumn(\n",
    "    \"last\",\n",
    "    expr(\"split(cleaned_name, ' ')[size(split(cleaned_name, ' ')) - 1]\")\n",
    ")\n",
    "\n",
    "df_flat = df_flat.drop(\"person_name\", \"person_name_cleaned\", \"name_parts_filtered\", \"cleaned_name\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "55859fc5-256c-4e21-98cf-bad1c6484e6b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Handling PII data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed71c38f-f22d-4516-b97f-0ee10d30a125",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def mask_dob(dob_str):\n",
    "    try:\n",
    "        dt = datetime.strptime(dob_str, \"%Y-%m-%d\")\n",
    "        return f\"{dt.year}-XX-XX\"\n",
    "    except Exception as e:\n",
    "        return None  # Handle invalid dates\n",
    "\n",
    "def mask_name(name):\n",
    "    return name[0] + \"*\" * (len(name) - 1) if name else \"\"  # Ensure empty names are handled\n",
    "\n",
    "def hash_column(column_name):\n",
    "    return sha2(col(column_name), 256)\n",
    "\n",
    "mask_dob_udf = udf(mask_dob, StringType())\n",
    "mask_name_udf = udf(mask_name, StringType())\n",
    "\n",
    "df_pii_handled = df_flat.withColumn(\n",
    "    \"dob_masked\", mask_dob_udf(col(\"dob\"))\n",
    ")\n",
    "\n",
    "df_pii_handled = df_pii_handled.withColumn(\n",
    "    \"first_name_masked\", mask_name_udf(col(\"first\"))\n",
    ").withColumn(\n",
    "    \"last_name_masked\", mask_name_udf(col(\"last\"))\n",
    ")\n",
    "\n",
    "df_pii_handled = df_pii_handled.withColumn(\n",
    "    \"cc_num_hashed\", hash_column(\"cc_num\")\n",
    ").withColumn(\n",
    "    \"street_hashed\", hash_column(\"street\")\n",
    ")\n",
    "\n",
    "df_pii_handled = df_pii_handled.drop(\"first\", \"last\", \"dob\", \"cc_num\", \"street\")\n",
    "\n",
    "df_pii_handled = df_pii_handled.withColumnRenamed(\"first_name_masked\", \"first\") \\\n",
    "                               .withColumnRenamed(\"last_name_masked\", \"last\") \\\n",
    "                               .withColumnRenamed(\"cc_num_hashed\", \"cc_num\") \\\n",
    "                               .withColumnRenamed(\"dob_masked\", \"dob\") \\\n",
    "                               .withColumnRenamed(\"street_hashed\", \"street\")\n",
    "\n",
    "df_pii_handled.display()\n",
    "df_pii_handled.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "37eca980-3fa8-42aa-9544-dd0391b60656",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Data Quality Checks\n",
    "\n",
    "this is a very simple check that I have been practicing through the years, it helps me quickly identify holes in the data, from here I will then reach out to the stakeholders to discuss the way forward, whether filling this in with 0, averages, median or any default values. (it will depend on what the field actually is)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ab0b831-f5bf-4ae7-8748-224b3405ca50",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "total_rows = df_pii_handled.count()\n",
    "\n",
    "summary_data = []\n",
    "for c in df_pii_handled.columns:\n",
    "    non_null_count = df_pii_handled.select(count(col(c)).alias(\"cnt\")).collect()[0][\"cnt\"]\n",
    "    null_count = total_rows - non_null_count\n",
    "    empty_string_count = df_pii_handled.filter(trim(col(c)) == \"\").count()\n",
    "\n",
    "    summary_data.append({\n",
    "        \"name\": c,\n",
    "        \"total\": total_rows,\n",
    "        \"non_nulls\": non_null_count,\n",
    "        \"nulls\": null_count,\n",
    "        \"empty_strings\": empty_string_count\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "display(summary_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a47e5428-ea61-4694-9148-4464ebe8a12a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Visualization and Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4028243-dfb2-4112-8156-c1ef4008ed56",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_pandas = df_pii_handled.toPandas()\n",
    "\n",
    "df_pandas[\"is_fraud\"] = pd.to_numeric(df_pandas[\"is_fraud\"], errors=\"coerce\")\n",
    "df_pandas[\"amt\"] = pd.to_numeric(df_pandas[\"amt\"], errors=\"coerce\")\n",
    "\n",
    "df_pandas = df_pandas.dropna(subset=[\"is_fraud\", \"amt\"])\n",
    "\n",
    "total_transactions = len(df_pandas)\n",
    "total_fraud_cases = df_pandas[\"is_fraud\"].sum()\n",
    "fraud_rate = total_fraud_cases / total_transactions * 100\n",
    "total_amount = df_pandas[\"amt\"].sum()\n",
    "fraud_amount = df_pandas[df_pandas[\"is_fraud\"] == 1][\"amt\"].sum()\n",
    "fraud_amount_pct = fraud_amount / total_amount * 100\n",
    "\n",
    "print(\"High-Level Summary Metrics:\")\n",
    "print(f\"Total Transactions: {total_transactions}\")\n",
    "print(f\"Total Fraud Cases: {total_fraud_cases} ({fraud_rate:.2f}%)\")\n",
    "print(f\"Total Transaction Amount: ${total_amount:.2f}\")\n",
    "print(f\"Fraudulent Transaction Amount: ${fraud_amount:.2f} ({fraud_amount_pct:.2f}%)\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "96d42750-ee4a-40a9-b06a-89a19559f5f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fraud_rate_by_category = df_pandas.groupby(\"category\")[\"is_fraud\"].mean().sort_values(ascending=False).reset_index()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=fraud_rate_by_category, x=\"is_fraud\", y=\"category\", palette=\"rocket\")\n",
    "plt.xlabel(\"Fraud Rate\")\n",
    "plt.ylabel(\"Merchant Category\")\n",
    "plt.title(\"Fraud Rate by Merchant Category\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "57840c07-b688-42e1-8047-2eb07d024130",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Transaction Amount Distribution (Fraud vs Non-Fraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d8a3f46-6f3e-496f-9969-28e02203c1b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df_pandas, x=\"is_fraud\", y=\"amt\", palette=\"Set2\")\n",
    "plt.xticks([0, 1], [\"Non-Fraud\", \"Fraud\"])\n",
    "plt.title(\"Transaction Amount Distribution: Fraud vs Non-Fraud\")\n",
    "plt.ylabel(\"Transaction Amount ($)\")\n",
    "plt.xlabel(\"Fraud Status\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d8034eaf-aac5-45ee-936f-f84c0cdd6f70",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##7-Day Rolling Average of Fraud\n",
    "Lets us see if fraud cases are on the rise, and plan ahead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc8ae36e-98d6-42e3-994d-3e0f0338d92b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_pandas[\"date\"] = pd.to_datetime(df_pandas[\"trans_date_trans_time\"]).dt.date\n",
    "\n",
    "daily_fraud = df_pandas.groupby(\"date\")[\"is_fraud\"].sum().rolling(window=7).mean()\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "daily_fraud.plot()\n",
    "plt.title(\"7-Day Rolling Avg of Fraud Cases\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Fraud Cases Count\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2e4f9a94-e584-434b-8f13-81e6c7f043e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Top 10 Fraudulent Merchants\n",
    "Simple targetting of merchant to be taken further actions, suspend / penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a977503-6d1d-49af-affd-536960944ba3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "top_merchants = df_pandas[df_pandas[\"is_fraud\"] == 1][\"merchant\"].value_counts().head(10)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "top_merchants.plot(kind=\"barh\", color=\"orange\")\n",
    "plt.xlabel(\"Fraud Cases\")\n",
    "plt.title(\"Top 10 Merchants with Most Fraud Cases\")\n",
    "plt.gca().invert_yaxis()  # To display the highest fraud merchant on top\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "76e31edd-12e9-4a82-b867-0ed3f4e2b5cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Handling PII Data: \n",
    "Clearly explain your chosen methods for managing\n",
    "personally identifiable information (PII).\n",
    "---------------------------------------------\n",
    "1) Date of Birth\n",
    "I kept just the year (e.g., “YYYY-XX-XX”) to allow for analysis like age-based trends, but removed the month and day to reduce the risk of identifying someone, especially when whoever it is has access to the other pieces of data.\n",
    "\n",
    "2) Name (First and Last): I masked part of the name (e.g., “Edward” → “E*****”) to keep things anonymous while still allowing for useful tasks like grouping or sorting.\n",
    "\n",
    "3) Credit Card Number and Street Address: I hashed these fields using SHA-256 to completely anonymize them while still keeping their uniqueness, allowing it to still be useful for analytical use.\n",
    "\n",
    "###These will largely depend on company policies, the stakeholders involved, and the specific use case of the data, some fields might not be tackled here, but are considered PII by company for example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2ec20a2d-ad60-4c11-8221-040fd7580eaf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Data Quality Assurance:\n",
    "Describe how you identify and process dirty\n",
    "data.\n",
    "\n",
    "Theres a part in my notebook that I have been practicing through the years, it helps me quickly identify holes in the data, from here I will then reach out to the stakeholders to discuss the way forward, whether filling this in with 0, averages, median or any default values. (it will depend on what the field actually is)\n",
    "\n",
    "In cases where we encounter more complex dirty data, like issues with names or other sensitive fields, those will need to be handled separately."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "paynet",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
